{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "121790e5-fda5-497e-a30c-f304e46393bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# To split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "torch.set_printoptions(precision=2, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c3541b4-57e5-4926-a1c5-26e854f59beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is important that your model and all data are on the same device.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check that MPS is available - Added for MacOS\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b38f230d-cf5d-4192-8083-cb5e0919ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data1(test_size=0.2, random_seed=42):\n",
    "    '''\n",
    "    returns:\n",
    "    - train_data_input: Tensor[N_train_samples, C, F]\n",
    "    - train_data_label: Tensor[N_train_samples, C, P]\n",
    "    - test_data_input:  Tensor[N_test_samples,  C, F]\n",
    "    - test_date_label:  Tensor[N_test_samples,  C, P]\n",
    "\n",
    "    where \n",
    "     - N_train_samples = number of train/test samples\n",
    "     - C = number of channels (here 1)\n",
    "     - F = number of features\n",
    "     - P = number of predicted features\n",
    "    '''\n",
    "    \n",
    "    data    = pd.read_csv(\"../../ICPSR_IHDS-1/Simon_Personal_Aggregates/basic_features.csv\")\n",
    "    \n",
    "    # Step 1: Replace ' ' and '' with -1\n",
    "    data = data.replace([' ', ''], -1)\n",
    "    # Step 2: Try to convert everything to numeric, forcing errors to NaN\n",
    "    data = data.apply(pd.to_numeric, errors='coerce')\n",
    "    # Step 3: Replace NaNs with -1\n",
    "    data = data.fillna(-1)\n",
    "\n",
    "    data_label = data['household_income']\n",
    "    data_input = data.drop(['household_income', 'person_id'], axis=1)\n",
    "\n",
    "    # Split data to get test and train set -> For generalization error prediction\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_input, data_label,\n",
    "        test_size=test_size,\n",
    "        random_state=random_seed\n",
    "    )\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X_train_np = X_train.to_numpy().astype(np.long)\n",
    "    X_test_np = X_test.to_numpy().astype(np.long)\n",
    "\n",
    "    y_train_np = y_train.to_numpy().astype(np.float32)\n",
    "    y_test_np = y_test.to_numpy().astype(np.float32)\n",
    "    \n",
    "    train_y_to = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "    test_y_to = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "    # Also prepare input_dict (for models expecting dict inputs)\n",
    "    X_dict_train = {col: torch.tensor(X_train[col].values, dtype=torch.long) for col in X_train.columns}\n",
    "    X_dict_test  = {col: torch.tensor(X_test[col].values, dtype=torch.long)  for col in X_test.columns}\n",
    "\n",
    "    return X_dict_train, train_y_to, X_dict_test, test_y_to\n",
    "    \n",
    "    # return datainp_to, datalab_to, input_dict\n",
    "    \n",
    "    \n",
    "\n",
    "X_train, y_train, X_test, y_test = get_data1()\n",
    "# get_data1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "42187d59-f6cd-43d6-88a0-0cafff927388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define embedding sizes according to your \"unique\" numbers\n",
    "        self.embeddings = nn.ModuleDict({\n",
    "            'stateid': nn.Embedding(33, 8),\n",
    "            'distid': nn.Embedding(61, 8),\n",
    "            'distname': nn.Embedding(375, 16),\n",
    "            'household_id': nn.Embedding(52, 8),\n",
    "            'sex': nn.Embedding(2, 2),\n",
    "            'attended_school': nn.Embedding(2, 2),\n",
    "            'enrolled_or_completed': nn.Embedding(2, 2),\n",
    "            'ever_repeated': nn.Embedding(2, 2),\n",
    "            'englisch_ability': nn.Embedding(3, 2),\n",
    "            'highest_degree': nn.Embedding(6, 4),\n",
    "            'caste': nn.Embedding(8, 4),\n",
    "            'hhassets': nn.Embedding(31, 8),\n",
    "        })\n",
    "\n",
    "        # Define linear layers for numerical features\n",
    "        self.numerical_features = ['age', 'years_of_education', 'Ann_earnings_tot']\n",
    "        \n",
    "        # Final linear layer after concatenating all embeddings + numericals\n",
    "        embedding_dim = (\n",
    "            8 + 8 + 16 + 8 + 2 + 2 + 2 + 2 + 2 + 4 + 4 + 8  # sum of embedding dimensions\n",
    "        )\n",
    "        numerical_dim = len(self.numerical_features)  # 3\n",
    "\n",
    "        total_input_dim = embedding_dim + numerical_dim\n",
    "\n",
    "        # Example simple MLP after concatenation\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(total_input_hdim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)  # Output: predict household_income\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is expected to be a dict with keys matching the feature names\n",
    "        embedded_features = []\n",
    "\n",
    "        for key, emb_layer in self.embeddings.items():\n",
    "            embedded = emb_layer(x[key])\n",
    "            embedded_features.append(embedded)\n",
    "\n",
    "        # concatenate all embeddings\n",
    "        embedded_features = torch.cat(embedded_features, dim=1)\n",
    "\n",
    "        # concatenate numerical features\n",
    "        numerical_data = [x[feature].unsqueeze(1) for feature in self.numerical_features]\n",
    "        numerical_data = torch.cat(numerical_data, dim=1)\n",
    "\n",
    "        # concatenate embeddings and numerical features\n",
    "        all_features = torch.cat([embedded_features, numerical_data], dim=1)\n",
    "\n",
    "        output = self.fc(all_features)\n",
    "        return output.squeeze(1)  # squeeze for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "11c8a14c-7192-48b2-9d99-374dcdcd8f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 91001), started 1:23:54 ago. (Use '!kill 91001' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ea021a1d8ab61cf7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ea021a1d8ab61cf7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "# !rm -rf ./runs/\n",
    "%tensorboard --logdir=runs\n",
    "\n",
    "'''\n",
    "Income\n",
    "• Mean: 59659.41\n",
    "• Minimum: -108327.80\n",
    "• Maximum: 6520261.00\n",
    "• Standard Deviation: 94614.89\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a56ca05e-1872-4ca6-8299-e356a48e2ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Train Loss: 10375127926.7215 - Test Loss: 7969774521.2681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 - Train Loss: 8294437176.6199 - Test Loss: 7410380710.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 - Train Loss: 7914178398.8728 - Test Loss: 7076260210.1570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 - Train Loss: 7666876834.5273 - Test Loss: 6893344716.2311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 - Train Loss: 7519837332.7401 - Test Loss: 6763514214.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 - Train Loss: 7414227238.0156 - Test Loss: 6669449389.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 - Train Loss: 7325945712.8128 - Test Loss: 6591909202.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 - Train Loss: 7255353080.5488 - Test Loss: 6529062913.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 - Train Loss: 7194111392.9848 - Test Loss: 6477950382.8385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Train Loss: 7142009443.5714 - Test Loss: 6441281684.4326\n",
      "Saving current state of the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 - Train Loss: 7105185495.2555 - Test Loss: 6412032908.3259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 - Train Loss: 7084901824.3797 - Test Loss: 6392507363.2711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 - Train Loss: 7067462968.6911 - Test Loss: 6377787908.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 - Train Loss: 7048717192.6852 - Test Loss: 6361872094.2933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 - Train Loss: 7034375751.4156 - Test Loss: 6346760004.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 - Train Loss: 7018482161.1806 - Test Loss: 6334201001.5289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 - Train Loss: 7005511100.6541 - Test Loss: 6324681175.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 - Train Loss: 6992817942.7809 - Test Loss: 6312049323.6148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 - Train Loss: 6981858867.3044 - Test Loss: 6301838302.9096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 - Train Loss: 6971121173.5706 - Test Loss: 6300750363.7333\n",
      "Saving current state of the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 - Train Loss: 6961944211.0078 - Test Loss: 6289214013.2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 - Train Loss: 6956097704.8395 - Test Loss: 6292134701.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 - Train Loss: 6952783954.7942 - Test Loss: 6280678870.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 - Train Loss: 6947200874.3344 - Test Loss: 6277924008.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 - Train Loss: 6942961605.4816 - Test Loss: 6272719456.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 - Train Loss: 6938808988.5947 - Test Loss: 6269638287.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 - Train Loss: 6935262167.6707 - Test Loss: 6265303677.4874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 - Train Loss: 6931517697.0085 - Test Loss: 6262138916.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 - Train Loss: 6926730934.5554 - Test Loss: 6259492518.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 - Train Loss: 6923563431.9140 - Test Loss: 6258990154.6193\n",
      "Saving current state of the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     82\u001b[39m             torch.save(model.state_dict(), \u001b[33m'\u001b[39m\u001b[33mNN_models/model_state.pt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m trained_model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m writer.close()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(input_dict_train, y_train, input_dict_test, y_test, n_epochs)\u001b[39m\n\u001b[32m     30\u001b[39m model.train()\n\u001b[32m     31\u001b[39m epoch_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_targets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTraining Epoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Split batch back into dict\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_input_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myvenvpy3/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myvenvpy3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:729\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_profile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;49;00m\n\u001b[32m    732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-arg]\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myvenvpy3/lib/python3.13/site-packages/torch/autograd/profiler.py:776\u001b[39m, in \u001b[36mrecord_function.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    771\u001b[39m     \u001b[38;5;28mself\u001b[39m.record = torch.ops.profiler._record_function_enter_new(\n\u001b[32m    772\u001b[39m         \u001b[38;5;28mself\u001b[39m.name, \u001b[38;5;28mself\u001b[39m.args\n\u001b[32m    773\u001b[39m     )\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001b[32m    777\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_callbacks_on_exit:\n\u001b[32m    778\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "def train_model(input_dict_train, y_train, input_dict_test, y_test, n_epochs=30):\n",
    "    # --- 1. Initialize model ---\n",
    "    model = Model()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    # --- 2. Set up training elements ---\n",
    "    criterion = torch.nn.MSELoss()  # For regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    batch_size = 64\n",
    "\n",
    "    # --- 3. Prepare training Dataset and DataLoader ---\n",
    "    input_features_train = torch.cat(\n",
    "        [input_dict_train[key].unsqueeze(1) for key in input_dict_train.keys()], dim=1\n",
    "    )\n",
    "    dataset_train = TensorDataset(input_features_train, y_train)\n",
    "    train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # --- 4. Prepare test data ---\n",
    "    input_features_test = torch.cat(\n",
    "        [input_dict_test[key].unsqueeze(1) for key in input_dict_test.keys()], dim=1\n",
    "    )\n",
    "    dataset_test = TensorDataset(input_features_test, y_test)\n",
    "    test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # --- 5. Training loop ---\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_inputs, batch_targets in tqdm(train_loader, desc=f\"Training Epoch {epoch}\", leave=False):\n",
    "            # Split batch back into dict\n",
    "            batch_input_dict = {}\n",
    "            idx = 0\n",
    "            for key in input_dict_train.keys():\n",
    "                batch_input_dict[key] = batch_inputs[:, idx].to(device).long()\n",
    "                idx += 1\n",
    "\n",
    "            batch_targets = batch_targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_input_dict)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        epoch_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "        # --- Evaluate on test set ---\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_inputs, batch_targets in tqdm(test_loader, desc=f\"Testing model in Epoch {epoch}\", leave=False):\n",
    "                batch_input_dict = {}\n",
    "                idx = 0\n",
    "                for key in input_dict_test.keys():\n",
    "                    batch_input_dict[key] = batch_inputs[:, idx].to(device).long()\n",
    "                    idx += 1\n",
    "\n",
    "                batch_targets = batch_targets.to(device)\n",
    "                outputs = model(batch_input_dict)\n",
    "                loss = criterion(outputs, batch_targets)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss = test_loss / len(test_loader)\n",
    "\n",
    "        # --- Print training and test loss ---\n",
    "        print(f'Epoch {epoch+1}/{n_epochs} - Train Loss: {epoch_loss:.4f} - Test Loss: {test_loss:.4f}')\n",
    "        \n",
    "        # Optional: log to tensorboard\n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "\n",
    "        # Save model every 10 epochs\n",
    "        if (epoch % 10 == 9):\n",
    "            print(\"Saving current state of the model\")\n",
    "            torch.save(model.state_dict(), 'NN_models/model_state.pt')\n",
    "\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(X_train, y_train, X_test, y_test)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Venv Kernel",
   "language": "python",
   "name": "myvenvpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
